{
  "title": "Infinity Embedding - Qwen3",
  "description": "High-throughput Qwen3-Embedding-0.6B (1024-dim) for Cylia NLU",
  "type": "serverless",
  "category": "embedding",
  "iconUrl": "https://dummyimage.com/100x100/a0a25a/fff&text=Q3",
  "config": {
    "runsOn": "GPU",
    "containerDiskInGb": 20,
    "gpuIds": "ADA_24",
    "gpuCount": 1,
    "allowedCudaVersions": ["12.9", "12.8", "12.7", "12.6", "12.5", "12.4"],
    "env": [
      {
        "key": "MODEL_NAMES",
        "input": {
          "name": "Model Names",
          "type": "string",
          "description": "One or more Hugging-Face model IDs. Separate multiple IDs with a semicolon.",
          "default": "Qwen/Qwen3-Embedding-0.6B"
        }
      },
      {
        "key": "BATCH_SIZES",
        "input": {
          "name": "Batch Sizes",
          "type": "string",
          "description": "Per-model batch size; semicolon-separated list matching MODEL_NAMES.",
          "default": "64"
        }
      },
      {
        "key": "BACKEND",
        "input": {
          "name": "Backend",
          "type": "string",
          "description": "Inference engine for all models: torch, optimum, or ctranslate2.",
          "default": "torch"
        }
      },
      {
        "key": "DTYPES",
        "input": {
          "name": "Data Types",
          "type": "string",
          "description": "Precision per model (auto, fp16, fp8). Semicolon-separated, must match MODEL_NAMES.",
          "default": "fp16"
        }
      },
      {
        "key": "INFINITY_QUEUE_SIZE",
        "input": {
          "name": "Infinity Queue Size",
          "type": "string",
          "description": "Max items queueable inside the Infinity engine.",
          "default": "48000"
        }
      },
      {
        "key": "RUNPOD_MAX_CONCURRENCY",
        "input": {
          "name": "Max Concurrency",
          "type": "string",
          "description": "Max concurrent requests the RunPod wrapper will accept.",
          "default": "300"
        }
      }
    ]
  }
}